{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dea677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2064ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data, mnist_info = tfds.load(name='mnist',with_info=True,as_supervised=True)\n",
    "number_validation_sample = tf.cast(0.1*mnist_info.splits['train'].num_examples,tf.int64)\n",
    "number_test_sample = mnist_info.splits['test'].num_examples\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /= 255.\n",
    "    return image,label\n",
    "scaled_train_and_validated_data = mnist_data['train'].map(scale)\n",
    "scaled_test_data = mnist_data['test'].map(scale)\n",
    "\n",
    "buffer_size = 10000\n",
    "shuffle_scale_train_and_validated_data = scaled_train_and_validated_data.shuffle(buffer_size)\n",
    "validate_data = shuffle_scale_train_and_validated_data.take(number_validation_sample)\n",
    "train_data = shuffle_scale_train_and_validated_data.skip(number_validation_sample)\n",
    "\n",
    "batch_size = 100\n",
    "train_data = train_data.batch(batch_size)\n",
    "validate_data = validate_data.batch(number_validation_sample)\n",
    "test_data = scaled_test_data.batch(number_test_sample)\n",
    "\n",
    "validation_inputs,validation_targets = next(iter(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "output_size = 10\n",
    "hidden_layer_size = 100\n",
    "max_number_epoch = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax'),\n",
    "                            ])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data,\n",
    "         epochs = max_number_epoch,\n",
    "         callbacks=[early_stopping], # early stopping\n",
    "         validation_data=(validation_inputs,validation_targets),\n",
    "         verbose=2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bda573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that this time the train, validation and test data are not iterable\n",
    "model.fit(train_inputs, # train inputs\n",
    "          train_targets, # train targets\n",
    "          batch_size=batch_size, # batch size\n",
    "          epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "          # callbacks are functions called by a task when a task is completed\n",
    "          # task here is to check if val_loss is increasing\n",
    "          callbacks=[early_stopping], # early stopping\n",
    "          validation_data=(validation_inputs, validation_targets), # validation data\n",
    "          verbose = 2 # making sure we get enough information about the training process\n",
    "          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_accuracy = model.evaluate(test_data)\n",
    "print('Test Loss = {:.2f}, Test Accuracy = {:.2f}'.format(test_loss,test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    " \n",
    "image_path=\"7.png\"\n",
    "im = image.load_img(image_path, target_size=(28, 28), color_mode = \"grayscale\")\n",
    "img = image.img_to_array(im)\n",
    "img = tf.expand_dims(img, axis=0)      \n",
    "img = scale(img, '')[0]\n",
    "prediction_indexes = (model.predict(img)[0])\n",
    "np.argmax(prediction_indexes, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff68c08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da2444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env]",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
